{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b285bdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as soup # https://realpython.com/beautiful-soup-web-scraper-python/\n",
    "import time\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcbedef",
   "metadata": {},
   "source": [
    "# GRAB ALL TICKERS INSIDE PRICE (MIN-MAX) RANGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7007fee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Pages[]: 6\n",
      "Elapsed Time: 10.003091096878052\n"
     ]
    }
   ],
   "source": [
    "pages = []\n",
    "tickers_list = []\n",
    "tickers_group_list = []\n",
    "\n",
    "ticker_skip = 1900\n",
    "price_min = 5.00\n",
    "price_max = 25.00\n",
    "valid_page_status = True\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "while (valid_page_status):    \n",
    "    \n",
    "    url =   f\"\"\"\n",
    "            https://www.marketwatch.com/tools/screener/stock?exchange=all&skip={ticker_skip}\n",
    "            &orderbyfield=&direction=desc\n",
    "            &visiblecolumns=Symbol,CompanyName,Price,NetChange,ChangePercent,Volume\n",
    "            &pricemin={price_min}&pricemax={price_max}\n",
    "            \"\"\" # must be inside while loop because {page_skip} won't update if outside of it...\n",
    "\n",
    "    page = requests.get(url)\n",
    "    soup_obj = soup(page.content, 'html.parser')\n",
    "    ticker_skip += 25\n",
    "    \n",
    "    cells_found = soup_obj.find(class_ = \"table__cell j-Symbol\")\n",
    "\n",
    "    if(cells_found):\n",
    "        pages.append(url)\n",
    "    else:\n",
    "        valid_page_status = False\n",
    "    \n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Length of Pages[]: {len(pages)}\")    \n",
    "print(f\"Elapsed Time: {elapsed_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e991894",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in pages:\n",
    "    page = requests.get(item)\n",
    "\n",
    "    df = pd.read_html(page.content)\n",
    "\n",
    "    tickers = df[0]\n",
    "    tickers = tickers[\"Symbol\"]\n",
    "    \n",
    "    for t in tickers:\n",
    "        tickers_list.append(t)\n",
    "        \n",
    "    tickers_group_list.append(tickers)\n",
    "    \n",
    "\n",
    "import csv    \n",
    "today = date.today()\n",
    "date_format = today.strftime(\"%b-%d-%Y\")\n",
    "file_name = \"tickers_\" + date_format\n",
    "\n",
    "with open(file_name, 'w') as f:\n",
    "     \n",
    "    write = csv.writer(f)\n",
    "    write.writerows(tickers_group_list) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9347b7c",
   "metadata": {},
   "source": [
    "# GRAB PRICE CHART TABLES FOR EVERY TICKER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71560805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                                                   0\n",
       " 0  Will be right back...  Thank you for your pati...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month = today.strftime(\"%B\").lower()\n",
    "year = today.strftime(\"%Y\")\n",
    "day = today.strftime(\"%d\")\n",
    "unix_time_yesterday = -1\n",
    "unix_time_5years = -1\n",
    "\n",
    "unix_converter_url = f\"https://timeconverter.online/list/{year}/{month}\"\n",
    "page = requests.get(unix_converter_url)\n",
    "soup_obj = soup(page.content, 'html.parser')\n",
    "table_rows = soup_obj.find_all(\"td\")\n",
    "\n",
    "# Get the unix time stamp for today's date\n",
    "for item in table_rows:\n",
    "    date_td = item.text.split(\" \")\n",
    "    if(date_td[0] == day):\n",
    "        unix_time_yesterday = item.find_previous().find_previous().text\n",
    "        # find_previous() written twice, since having been read already, the iterator has moved\n",
    "        \n",
    "year = str((int(year) - 5))\n",
    "unix_converter_url = f\"https://timeconverter.online/list/{year}/{month}\"\n",
    "page = requests.get(unix_converter_url)\n",
    "soup_obj = soup(page.content, 'html.parser')\n",
    "table_rows = soup_obj.find_all(\"td\") \n",
    "\n",
    "# Get the unix time stamp for date from 5 years ago\n",
    "for item in table_rows:\n",
    "    date_td = item.text.split(\" \")\n",
    "    if(date_td[0] == day):\n",
    "        unix_time_5years = item.find_previous().find_previous().text\n",
    "        \n",
    "main_url = f\"https://finance.yahoo.com/quote/{tickers_list[0]}?p={tickers_list[0]}\"\n",
    "        \n",
    "base_url = f\"https://finance.yahoo.com/quote/{tickers_list[0]}/history?p={tickers_list[0]}\"\n",
    "\n",
    "weekly_url =    f\"\"\"\n",
    "                https://finance.yahoo.com/quote/{tickers_list[0]}/history?\n",
    "                period1={unix_time_5years}&period2={unix_time_yesterday}\n",
    "                &interval=1wk&filter=history&frequency=1wk\n",
    "                &includeAdjustedClose=true    \n",
    "                \"\"\"\n",
    "# Yahoo Finance blocking scraping here????\n",
    "page = requests.get(main_url)\n",
    "\n",
    "df = pd.read_html(page.content)\n",
    "\n",
    "soup_obj = soup(page.content, 'html.parser')\n",
    "table_rows = soup_obj.find_all(\"td\")\n",
    "print(table_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eddf198",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
